\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Stock Market Prediction using LSTM \\
{\footnotesize Homework 1 of Artificial Neural Network}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{ Rohit Das\\
\textit{Student ID -61047086s}\\
\IEEEauthorblockA{\textit{Computer Science and Engineering} \\
\textit{National Taiwan Normal University}\\
Taipei City, Taiwan \\
rdas.879@gmail.com}
}

\maketitle

\begin{abstract}
This report provides a detailed information of LSTM model
used in predicting the closing price of a company enlisted in stock market .
\end{abstract}

\begin{IEEEkeywords}
Artificial Neural Network, RNN, LSTM
\end{IEEEkeywords}

\section{Introduction}
This is the report of first homework of Artificial Neural Network course in National Taiwan Normal University. The main goal of this project is predicting the closing price of LOTUS pharmaceuticals for consecutive 5 days.

\section{Methods}
Recurrent Neural Networks(RNN) is an advanced for of Neural Networks that has internal memory that makes it capable of processing long sequences. This makes RNN very suitable for stock price prediction,which involves long historical data.However, RNNs suffer from the problem of vanishing gradients, which hampers learning of long data sequences. 
Here LSTM is introduced to tackle this problem.It is capable of handling the vanishing gradient problem faced by RNN.

\section{Experiment}
The LSTM model used in this experiment contains two layers and are Fully Connected(FC).
The lookback value I used is 5 days closing prices(a month). 16 neurons are added as hidden dimensions with dropout value 0.5 to prevent overfitting. Activation Function used is tanh.

\section{Results}
The results are all created in \href{https://colab.research.google.com/drive/1kApFFux015DephOrstKH78dwabvSI3a-#scrollTo=QGhHzVegqJsE}{Google Colab} :
The results generated from the model shows that after 2000 epochs, we can see that the loss has started to decrease to 0. The model generated Train Score: 258.69 RMSE(Root Mean Square Error) and Test Score: 277.30 RMSE. Below is the graphical visualization of the actual value and predicted value.
\begin{figure}[htbp]
\includegraphics[width = 10cm]{Figure 1.PNG}
\caption{Prediction and Training Loss}
\label{fig1}
\end{figure}

\section{Conclusion}
Stock market prediction with Neural Networks is interesting but very difficult with only 1 feature. Volume can also play an important role in predicting the values. Co-relating these two features can result in much better accuracy. If we can train the model on some statistics maybe we can have some better accuracy in prediction. I thank professor Yeh for giving me this opportunity to learn something fascinating and new.
\section{References}
Some website references:
\begin{enumerate}
  \item \href{https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/}{A Gentle Introduction to Long Short-Term Memory Networks by the Experts}
  \item \href{https://en.wikipedia.org/wiki/Recurrent_neural_network}{Recurrent Neural network: Wikipedia}
  \item \href{https://towardsdatascience.com/stock-prediction-using-recurrent-neural-networks-c03637437578}{Stock prediction using recurrent neural networks}
  \item \href{https://www.analyticsvidhya.com/blog/2021/03/introduction-to-long-short-term-memory-lstm/}{Introduction to Long Short Term Memory}
  \item \href{https://medium.com/swlh/stock-price-prediction-with-pytorch-37f52ae84632}{Stock Price Prediction with PyTorch}
\end{enumerate}

\end{document}
